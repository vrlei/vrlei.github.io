<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="alternate" type="application/rss+xml" title="VRLei.COM - 虚拟现实门户网" href="https://jysperm.me/atom.xml"><link rel="stylesheet" href="/styles.css"><title>让980跑出1080的效果 七鑫易维推出VR眼控新品|眼球|效果|技术_新浪新闻
 | VRLei.COM - 虚拟现实门户网</title></head><body><div class="container"><div class="columns page-header"><h1>VRLei.COM - 虚拟现实门户网</h1></div><div class="columns"><div class="navigation"><nav class="menus-main"><a href="/" class="favicon"><img alt="VRLei.COM - 虚拟现实门户网" src="/favicon.png"></a><a href="/">首页</a></nav></div></div><div class="columns"><div class="block-body column three-fourths"><article><header><small class="right"><a target="_blank" href="null_posts%2F1567226357.md">查看源代码</a></small><h1>让980跑出1080的效果 七鑫易维推出VR眼控新品|眼球|效果|技术_新浪新闻
</h1></header><div class="article-meta clearfix"><time class="left">2018-02-05</time><ul class="tags left"><li><a href="/categories/vr-e8-b5-84-e8-ae-af/">vr%e8%b5%84%e8%ae%af</a></li></ul><ul class="tags right"></ul></div><div class="markdown-body"><p>　　原标题：让980跑出1080的效果 七鑫易维推出VR眼控新品</p>
<p>　　 让980跑出1080的效果 七鑫易维推出VR眼控新品</p>
<p>　　让980跑出1080的效果，七鑫易维推出VR眼控新品 | GTC China 2016</p>
<p>　　对VR来说，交互是一个重要的创新点，GPU性能则是重要的瓶颈，对于前者目前仍有很多创业公司在发布新的交互系统，后者则是GPU巨头英伟达需要努力的的地方。</p>
<p>　　9月13日在英伟达举办的GPU技术大会(GTC China 2016)上，拥有眼球追踪技术的国内创业公司七鑫易维发布了首款针对HTC Vive的眼控外设，把这项技术应用到了VR上面。</p>
<p>　　这款号称全球首款VR眼配件的产品，为VR带来两大功能：眼控交互和注视点渲染，前者为VR带来了新的交互式，后者则通过新的渲染方式提高GPU的渲染效率。</p>
<p>　　眼控：陀螺仪的升级版？</p>
<p>　　最早的Cardboard在交互上非常简单，用户转动头部使画面移 动，同时移 动光标来选定某个物体，这是利用了手机内置的陀螺仪实现。眼球追踪的加入让这种交互有了升级，除了转动头部，用户在头部不动的时候，也可以通过注视视野中的不同物体来进行选择。</p>
<p>　　为了追踪用户的眼球运动，七鑫易维推出了这款内置到HTC Vive里的配件，它是一个叠加到头盔透镜上面的产品。一对设备上各自有一个传感器(摄像头)，设计在下方;环绕着透镜的则是一圈红外补光灯，因为VR头盔是全封闭的;另外它还有一个USB Type-C接口用作供电和数据传输。摄像头之所以被设计在下方，据七鑫易维CEO黄通兵透露，是因为要考虑用菲涅尔透镜的头盔，它的同心圆纹理会有干扰，所以就做在下面。</p>
<p>　　在追踪方面，这款产品支持全视场角的追踪，能覆盖整个VR显示屏幕;拥有220HZ渲染频率，延时低;同时支持近视镜片叠加，使用户不用佩戴眼镜也能玩，同时避免近视眼镜对眼球追踪的影响。</p>
<p>　　为了提高眼球追踪的可用性，该公司在算法方面引入了深度学习技术，据黄通兵介绍，</p>
<p>　　在深度学习出来之前，SVM等机器学习的传统方法效果做不到很好，因为其中的很多特征是人为设定的，实际有很多情况可能不是那样的。深度学习的好处是机器可以自动去学习，不限定特征，这样的话基于大量的样本进行训练可以得到一个很牛的模型，这个模型可以用来进行人眼的眼球追踪。</p>
<p>　　以前的技术可以识别人眼的可用率在95%，一万个人中可能有500个人用不了，这样要把它用在消费级就不行了，特殊行业可以。要把眼球追踪用到消费级的话必须达到更高的可用性，深度学习可以把它的可用性从95%提升到99.9%甚至更高。</p>
<p>　　开发者更关注注视点渲染</p>
<p>　　虽说眼球交互听起来非常炫酷，实际使用时并不如动捕手柄+空间定位自然，如上文所说，它更像是陀螺仪的升级版。实际上，开发者对眼球追踪技术的期待，更多是注视点渲染。黄通兵表示开发者对他们这套系统的功能关注度排序分别是：注视点渲染，交互和眼动分析。</p>
<p>　　注视点渲染(也叫焦点渲染)通过近红外传感器对人的眼球进行追踪，判断人眼的注视点，只对注视点区域进行高清渲染，而且这个区域会随着注视点的变化而变化。这项技术在英伟达MRS(multi-resolution shading)技术的基础上进一步缩小渲染范围，从而大幅提高渲染效率。</p>
<p>　　黄通兵表示，VR看房开发者指挥家使用这套系统之后，“本来要1080的显卡才能跑得动的场景，加上眼球追踪可能用980就能跑，这样一方面大幅降低他们的硬件成本，同时可以提高视觉效果，可以上复杂的光照等各种特效”。当然，实际的效果还是要看开发者的不同情况而定。</p>
<p>　　更需要降低GPU性能需求的应该是移 动VR，而移 动VR十分需要考虑功耗和性能的平衡。黄通兵表示，“做到移 动VR上，原理上差不多，结构上需要改一改。移 动VR上功耗性能有限制，所以这块一般会把帧率适当降低，其实也可以跑满帧，但移 动VR本身帧率就低，所以就没有必要跑满帧。”</p>
<p>　　据介绍，这套产品单眼追踪的功耗不到500mW，如果工作在省电模式下会更低。而对处理性能的要求黄通兵表示高通的骁龙820是支持的，“主流的都没问题”。</p>
<p>　　不过这套产品不会出单卖的消费版，它预计将在10月份登陆京东众筹，售价3000元左右，主要面向开发者。而面向消费者的产品将会以与头盔厂商的合作，内置到后者产品当中的形式推出。具体的产品面世时间仍有待确定，但据悉高通的一体机方案会重点推这个技术，国内的大朋和3Glasses也很积极。</p>
<p><strong>该文章由WP-AutoPost插件自动采集发布</strong></p>
<p><strong>原文地址:</strong></p>
</div></article></div><div class="block-sidebar column one-fourth"><div class="widget tags"></div><div class="widget archives"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">270</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a><span class="archive-list-count">106</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">84</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">108</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">284</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a><span class="archive-list-count">71</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">126</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">90</span></li></ul></div><div class="widget text-content"><p>该博客使用基于 &nbsp;<a href="http://hexo.io">Hexo</a>&nbsp; 的 &nbsp;<a href="https://github.com/jysperm/hexo-theme-simpleblock">simpleblock</a>&nbsp; 主题。博客内容使用 &nbsp;<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn">CC BY-NC-SA 3.0</a>&nbsp; 授权发布。最后生成于 2018-02-06.</p></div></div></div></div></body></html>